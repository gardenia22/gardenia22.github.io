<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">
<head>
    <meta charset="utf-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="description" content="">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


<meta name="keywords" content="">

 
<meta property="og:type" content="article"/>
<meta property="og:description" content=""/>
<meta property="og:title" content="神经网络 : nanshu.wang"/>
<meta property="og:site_name" content="nanshu wang blog"/>
<meta property="og:image" content="" />
<meta property="og:image:type" content="image/jpeg" />
<meta property="og:image:width" content="" />
<meta property="og:image:height" content="" />
<meta property="og:url" content="http://nanshu.wang/tags/e7a59ee7bb8fe7bd91e7bb9c/">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2015-03-26"/>
<meta property="article:modified_time" content="2015-03-26"/>






    <base href="http://nanshu.wang">
    <title> 神经网络 - nanshu.wang </title>
    <link rel="canonical" href="http://nanshu.wang/tags/e7a59ee7bb8fe7bd91e7bb9c/">
    <link href="http://nanshu.wang/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="alternate" type="application/rss+xml" title="神经网络" />

    <link href='http://fonts.useso.com/css?family=Fjalla+One|Open+Sans:300' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/static/css/style.css">

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
    <script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?a79535ca63291dc820e3ecefa615aad1";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>

</head>

<body lang="en">
<header id="header">
	<nav id="nav">
	<div id="title"><a href="/">Nanshu Wang</a></div>
    <div><a href=mailto: nanshu.wang@gmail.com target="_blank" class="mailto"> </span> <span class="icon-mail"></span>gardenia22</a></div>
	</nav>
    <nav id="nav">
    	        <ul id="mainnav">
            <li>
                <a href="/蘅芜/">
                <span class="icon"> <i aria-hidden="true" class="icon-pencil"></i></span>
                <span> 蘅芜 </span>
            </a>
            </li>
            <li>
            <a href="/潇湘/">
                <span class="icon"> <i aria-hidden="true" class="icon-quill"></i></span>
                <span> 潇湘 </span>
            </a>
            </li>
            <li>
            <a href="/观叹/">
                <span class="icon"> <i aria-hidden="true" class="icon-leaf"></i></span>
                <span> 观叹 </span>
            </a>
            </li>
            <li>
            <a href="/about">
                <span class="icon"> <i aria-hidden="true" class="icon-heart"></i></span>
                <span> 关于 </span>
            </a>
            </li>
        </ul>

    </nav>
    <nav id="nav">
       	        <ul id="social">
            
            <li id="share">
                <span class="title"> 友链 </span>
                <div class="dropdown share">
                    <ul class="social">
                      <li> <a href="http://xgezhang.com" target="_blank" title="xge技术博客" class="twitter">xge</a> </li>
                      <li> <a href="http://spf13.com" target="_blank" title="spf13 is Steve Francis" class="facebook">spf13</a> </li>
                      <li> <a href="http://libaier.net" target="_blank" title="Libaier" class="rss">Libaier</a> </li>
                      <li> <a href="http://read.douban.com/column/195295/" target="_blank" title="100个故事" class="douban">一百个故事</a></li>
                    </ul>
                <span class="icon icon-bubbles"> </span> <span class="subcount"></span> </div>
            </li>
    
            <li id="follow">
                <span class="title"> 驻留地 </span>
                <div class="dropdown follow">
                    <ul class="social">
                        

                        <li> <a href="http://weibo.com/gardenia22/" target="_blank" title="微博" class="weibo">微博</a> </li>
                        <li> <a href="http://www.douban.com/people/gardenia22" target="_blank"
                        title="豆瓣" class="douban">豆瓣</a> </li>
                        <li> <a href="http://www.zhihu.com/people/gardenia" target="_blank" title="知乎" class="zhihu">知乎</a> </li>
                        <li> <a href="http://github.com/gardenia22" target="_blank" title="GitHub" class="github">GitHub</a> </li>                         
                        <li> <a href="http://www.facebook.com/gardenia.nanshu.wang" target="_blank" title="Facebook" class="facebook"> Facebook</a></li>
                        <li> <a href="http://instagram.com/ainedrag22" target="_blank" title="Instagram" class="instagram">Instagram</a> </li>
                                                                       
                        
                    </ul>
                <span class="icon icon-rocket"> </span> <span class="subcount"></span> </div>
            </li>

        </ul>

	</nav>
</header>


<section id="main">
  <div>
   <h1 id="title">神经网络</h1>
    
        <article class="post">
    <header>
      <h2><a href="http://nanshu.wang/post/2015-03-23">机器学习笔记5 神经网络2 参数学习 </a> </h2>
      <div class="post-meta">Thu, Mar 26, 2015 </div>
    </header>
    <article itemprop="articleBody" id="content">
    	Andrew Ng cs229 Machine Learning 笔记 成本函数(Cost Function) 以下是我们会用到的一些变量： $L$表示神经网络的层数 $s_l$表示第$l$层的神经单元数(不包括偏差(bias)单元) $K$表示输出单元数(分类数) 当有多个输出类别时，采用$h_\Theta(x)_k$表示第$k$个输出的假设结果。 神经网络的成本函数是logistic回归中的成本函数更普遍的一种形式。 logistic回归中的成本函数为： $$J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m y^{(i)}\log(h_{\theta}) + (1-y^{(i)}) \log(1-h_{\theta}(x^{(i)})) \right] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2$$ 神经网络的成本函数稍微复杂一点： $$\begin{gather*} J(\Theta) = - \frac{1}{m} \left[ \sum_{i=1}^m \sum_{k=1}^K y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2 \end{gather*}$$ 和logistic回归相比，第一个方括号内多了一层累加求和，即对多类输出节点的成本函数进行累加，会遍历所有的输出节点。 正则化的部分则是将每一层的参数都考虑了进去(包括偏差单元相关的参数值)。和logistic回归一样，每一项都进行了平方。 注意: 双层累加中对于输出层所有单元的logistic回归的成本函数进行求和 三层累加中则是对于整个神经网络中单独的$\Theta$参数的平方进行求和 三层累加中的$i$和训练集中的$i$并不一样 向后传播(Backpropagation)算法 向后传播是神经网络中表示最小化成本函数的术语，就像logistic回归和线性回归中的梯度下降(gradient descent)一样。 我们的目标是计算： $$\min_\Theta J(\Theta)$$ 即我们想最小化成本函数$J$，得到最优化参数$\Theta$。 观察我们用于计算$J(\Theta)$偏导的等式：
	</article>
    <footer>
        <a href='http://nanshu.wang/post/2015-03-23'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
        <article class="post">
    <header>
      <h2><a href="http://nanshu.wang/post/2015-03-03-2">机器学习笔记5 神经网络1 模型表达 </a> </h2>
      <div class="post-meta">Tue, Mar 3, 2015 </div>
    </header>
    <article itemprop="articleBody" id="content">
    	<p>Andrew Ng cs229 Machine Learning 笔记</p>

<h1 id="神经网络:d35c8128725ed53542064246ed42d2c0">神经网络</h1>

<h2 id="非线性假设:d35c8128725ed53542064246ed42d2c0">非线性假设</h2>

<p>在特征变量数较大的情况下，采用线性回归会很难处理，比如我的数据集有3个特征变量，想要在假设中引入所有特征变量的平方项：</p>

<div>
$$g(\theta_0 + \theta_1x_1^2 + \theta_2x_1x_2 + \theta_3x_1x_3  + \theta_4x_2^2 + \theta_5x_2x_3  + \theta_6x_3^2 )$$
</div>

<p>共有6个特征，假设我们想知道选取其中任意两个可重复的平方项有多少组合，采用允许重复的组合公式计算$\frac{(n+r-1)!}{r!(n-1)!}$，共有$\frac{(3 + 2 - 1)!}{(2!\cdot (3-1)!)} = 6$种特征变量的组合。对于100个特征变量，则共有$\frac{(100 + 2 - 1)!}{(2\cdot (100-1)!)} = 5050$个新的特征变量。</p>

<p>可以大致估计特征变量的平方项组合个数的增长速度为$\mathcal{O}(\frac{n^2}2)$，立方项的组合个数的增长为$\mathcal{O}(n^3)$。这些增长都十分陡峭，让实际问题变得很棘手。</p>

<p>在变量假设十分复杂的情况下，神经网络提供了另一种机器学习算法。</p>

	</article>
    <footer>
        <a href='http://nanshu.wang/post/2015-03-03-2'><nobr>Read more →</nobr></a>
    </footer>
</article>

    
  </div>
</section>

<aside id="meta"> </aside>

<footer>
  <div>
    <p>
    &copy; 2015 <span itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Nanshu Wang.</span></span>
        Powered by <a href="http://hugo.spf13.com">Hugo</a>.
        Theme by <a href="http://spf13.com">Steve Francia</a>.
    </p>
  </div>
</footer>
<script type="text/javascript">
(function(){var j=function(a,b){return window.getComputedStyle?getComputedStyle(a).getPropertyValue(b):a.currentStyle[b]};var k=function(a,b,c){if(a.addEventListener)a.addEventListener(b,c,false);else a.attachEvent('on'+b,c)};var l=function(a,b){for(key in b)if(b.hasOwnProperty(key))a[key]=b[key];return a};window.fitText=function(d,e,f){var g=l({'minFontSize':-1/0,'maxFontSize':1/0},f);var h=function(a){var b=e||1;var c=function(){a.style.fontSize=Math.max(Math.min(a.clientWidth/(b*10),parseFloat(g.maxFontSize)),parseFloat(g.minFontSize))+'px'};c();k(window,'resize',c)};if(d.length)for(var i=0;i<d.length;i++)h(d[i]);else h(d);return d}})();
fitText(document.getElementById('title'), 1)
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

</body>
</html>

